---
layout: post
title: 英伟达在AI芯片领域的垄断被打破…随着谷歌、微软、Meta纷纷加入战团，步入战国时代
date: 2025-11-28 02:16:04.000000000 +00:00
link: https://cnnews.chosun.com/client/news/viw.asp?nNewsNumb=20251163908&cate=&mcate=
categories: chosun
---

<div>2025-11-28&nbsp;10:03  &nbsp;</div><div id="articleBody" itemprop="articleBody">
							
								<div >	
									<dl>		
										<dt><img src="https://images.weserv.nl/?url=cnnews.chosun.com/up_fd/wc_news/2025-11/bimg_thumb/2chautA(2).jpg"></dt>
										<dd>▲ 谷歌TPU</dd>
									</dl>
								</div>
							

						<!-- 
							<audio id="player1" controls src="/up_fd/wc_news/" ></audio>
							<audio id="player2" controls src="/up_fd/wc_news/" ></audio>
						-->
						<!-- 
							<div >
							</div> 
						-->

								“像PC时代的Windows一样引领AI（人工智能）时代的OS（操作系统）。”<br /><br />这是定义英伟达GPU（图形处理设备）的句子。能够同时处理大量数据的GPU已成为AI时代的必备产品，而率先将GPU推向市场的英伟达也因此登上了AI最强者的宝座。在基于GPU的AI芯片市场上，英伟达的市场份额高达90&#37;。每片GPU的价格高达3万-4万美元（约合4000万至5000万韩元），非常昂贵，有钱也很难买到GPU。所以，英伟达成为了世界上最赚钱的企业。<br /><br />但最近主要的大型科技公司开始自行开发定制型芯片（ASIC）或实现半导体供应商多元化，英伟达AI帝国的地位开始出现动摇的迹象。ASIC是针对特定用途的专用芯片，在电力效率和成本方面比英伟达的GPU更有优势。AI开发的模式从需要大量计算能力的“学习”阶段转向相对耗资较少的“推理”阶段，这也给英伟达的垄断格局制造了裂痕。因为与学习不同，在推理过程中，电力效率高的定制芯片更为合适。<br /><br /><b>可替代英伟达的定制化AI芯片</b><br /><br />谷歌发布AI模型“Gemini 3”时，与AI模型同样受到关注的是谷歌的定制芯片TPU（张量处理单元）。TPU是谷歌大约10年前为支持自身的AI开发所制造的高性能半导体。谷歌负责TPU的基本设计，美国芯片设计公司博通和台湾联发科则负责芯片的物理设计。其中搭载了SK海力士、三星电子、美光等公司的HBM（高带宽存储器）。这些组件由台湾的台积电最终组装生产成产品。由于专门用于AI，在某些任务中比GPU的性能更高，且功耗低，可以降低运营成本。AI初创公司Anthropic计划使用最多100万个TPU来开发AI模型，据说Meta也将在其自有数据中心引入谷歌的TPU。<br /><br /><DIV ><dl ><dt><img src="http://cnnews.chosun.com/up_fd/wc_News/2025-11/limg_org/2chautB(3).jpg" ></dt><dd class=use_caption>▲ 制图 = 朴祥勋 </dd></dl></DIV>  OpenAI正在与博通开展合作，计划在明年年底前生产自己的芯片。因为投资5000亿美元建设数据中心的“星际之门”项目需要大量芯片。Meta正在开发自己的AI芯片“MTIA”，将其应用于AI开发和AI服务。亚马逊云科技（AWS）正在运营配备了50万个“Trainium 2”的自有AI数据中心，其主要客户有Anthropic和Databricks等。阿里巴巴和百度等中国公司也正在使用自主研发的芯片进行AI模型训练，以降低对英伟达的依赖。<br /><br /><b>AI生态系统或将发生改变</b><br /><br />摆脱英伟达的趋势在很大程度上出于经济原因。定制芯片比GPU更便宜，能效也更好，有利于运营。摩根士丹利称，安装24,000片英伟达最新版Blackwell GPU需要8.52亿美元（约1.2万亿韩元），而相同规模的谷歌TPU的安装费用仅为9900万美元（约1450亿韩元）。廉价芯片的出现有望缓解近期因对人工智能基础设施的过度投资而引发的对人工智能泡沫的担忧。<br /><br />AI从学习转向推理的模式转变也在产生影响。在制作AI模型的初期，重要的是“学习”海量数据。因此，需要大量高性能的英伟达GPU。但在基于已制作的AI提供服务的“推理”阶段，不再需要GPU这种高性能产品。这就是TPU或NPU（神经网络处理装置）等功耗效率高、轻便的半导体受到青睐的原因。科技行业人士说：“虽然目前许多企业在同时使用英伟达GPU和其他企业的自研芯片，但英伟达GPU的比重似乎正在逐渐降低。”但目前的主流观点认为，英伟达GPU的性能仍然优于其他自研芯片。<br /><br />以英伟达为中心的AI生态系统似乎也将发生改变。目前，英伟达设计的芯片由台积电生产，这一结构已经被固定下来。像博通这样由大型科技公司与设计公司携手合作，自行生产的设计公司正作为竞争对手崭露头角。<br /><br /><b>☞CPU, GPU, TPU, NPU </b><br /><br />作为计算机基本大脑的CPU（中央处理器）就像一个能轻松做出韩式、日式、中式等各种菜肴的天才厨师。它独自完成所有工作，因此有一个缺点就是耗时较长。相比之下，GPU（图形处理器）虽然实力稍逊，但它拥有1000名手脚麻利的兼职生同时上阵，能快速制作特定菜肴的能力。在AI时代，需要大量数据进行简单重复的计算和学习，这就是GPU受到关注的原因。雇佣1000名兼职生，成本（电费）很高，而且需要很大的空间。TPU（张量处理单元）是谷歌为开发AI而打造的高性能半导体。与CPU、GPU不同，它更像只擅长做一道特定菜肴（比如包饺子）的专用机器。虽然不需要像GPU那样雇佣很多兼职生，但仍然需要一个大工厂。NPU（神经网络处理单元）是模仿人类大脑的半导体。它体积小、重量轻、耗电量少、效率高，非常适合智能手机和家电产品。
							</div>
